(set-logic HORN)


(declare-fun |combined_lturn| ( (_ BitVec 32) (_ BitVec 32) (_ BitVec 32) (_ BitVec 32) (_ BitVec 32) (_ BitVec 32) (_ BitVec 32) (_ BitVec 32) (_ BitVec 32) (_ BitVec 32) (_ BitVec 32) (_ BitVec 32) (_ BitVec 32) (_ BitVec 32) ) Bool)
(declare-fun |CHC_COMP_FALSE| ( ) Bool)
(declare-fun |step_lturn| ( (_ BitVec 32) (_ BitVec 32) (_ BitVec 32) (_ BitVec 32) (_ BitVec 32) (_ BitVec 32) (_ BitVec 32) (_ BitVec 32) (_ BitVec 32) (_ BitVec 32) (_ BitVec 32) (_ BitVec 32) (_ BitVec 32) (_ BitVec 32) ) Bool)
(declare-fun |lturn| ( (_ BitVec 32) (_ BitVec 32) (_ BitVec 32) (_ BitVec 32) (_ BitVec 32) (_ BitVec 32) (_ BitVec 32) (_ BitVec 32) (_ BitVec 32) (_ BitVec 32) (_ BitVec 32) (_ BitVec 32) (_ BitVec 32) (_ BitVec 32) ) Bool)

(assert
  (forall ( (A (_ BitVec 32)) (B (_ BitVec 32)) (C (_ BitVec 32)) (D (_ BitVec 32)) (E (_ BitVec 32)) (F (_ BitVec 32)) (G (_ BitVec 32)) (H (_ BitVec 32)) (I (_ BitVec 32)) (J (_ BitVec 32)) (K (_ BitVec 32)) (L (_ BitVec 32)) (M (_ BitVec 32)) (N (_ BitVec 32)) ) 
    (=>
      (and
        (and (bvsle #x00000000 (bvadd #xfffffff5 D F))
     (bvsle #x00000000 (bvadd #xfffffff6 I F))
     (bvsle #x00000000 (bvadd #xfffffff6 D L))
     (bvsle #x00000000 (bvadd #xfffffff6 D K))
     (bvsle #x00000000 (bvadd #xfffffff7 I L))
     (bvsle #x00000000 (bvadd #xfffffff7 I K))
     (bvsle #x00000000 (bvadd #xfffffff7 F L))
     (bvsle #x00000000 (bvadd #xfffffff7 F K))
     (bvsle #x00000000 (bvadd #xfffffff7 D N))
     (bvsle #x00000000 (bvadd #xfffffff7 D G))
     (bvsle #x00000000 (bvadd #xfffffff7 D A))
     (bvsle #x00000000 (bvadd #xfffffff7 D J))
     (bvsle #x00000000 (bvadd #xfffffffc (bvmul #xffffffff H) I))
     (bvsle #x00000000 (bvadd #xfffffffc (bvmul #xffffffff H) F))
     (bvsle #x00000000 (bvadd #xfffffffc (bvmul #xffffffff C) I))
     (bvsle #x00000000 (bvadd #xfffffffc (bvmul #xffffffff C) F))
     (bvsle #x00000000 (bvadd #xfffffffc N H))
     (bvsle #x00000000 (bvadd #xfffffffc H G))
     (bvsle #x00000000 (bvadd #xfffffffc H J))
     (bvsle #x00000000 (bvadd #xfffffffc E B))
     (bvsle #x00000000 (bvadd #xfffffffc D (bvmul #xffffffff E)))
     (bvsle #x00000000 (bvadd #xfffffffc D (bvmul #xffffffff B)))
     (bvsle #x00000000 (bvadd #xfffffffc C N))
     (bvsle #x00000000 (bvadd #xfffffffc C G))
     (bvsle #x00000000 (bvadd #xfffffffc C A))
     (bvsle #x00000000 (bvadd #xfffffffc C J))
     (bvsle #x00000000 (bvadd #xfffffffc A H))
     (bvsle #x00000000 (bvadd #xfffffffb N B))
     (bvsle #x00000000 (bvadd #xfffffffb H L))
     (bvsle #x00000000 (bvadd #xfffffffb H K))
     (bvsle #x00000000 (bvadd #xfffffffb E N))
     (bvsle #x00000000 (bvadd #xfffffffb E G))
     (bvsle #x00000000 (bvadd #xfffffffb E A))
     (bvsle #x00000000 (bvadd #xfffffffb E J))
     (bvsle #x00000000 (bvadd #xfffffffb D (bvmul #xffffffff H)))
     (bvsle #x00000000 (bvadd #xfffffffb D (bvmul #xffffffff C)))
     (bvsle #x00000000 (bvadd #xfffffffb C L))
     (bvsle #x00000000 (bvadd #xfffffffb C K))
     (bvsle #x00000000 (bvadd #xfffffffb B G))
     (bvsle #x00000000 (bvadd #xfffffffb B J))
     (bvsle #x00000000 (bvadd #xfffffffb A B))
     (bvsle #x00000000 (bvadd #xfffffff8 N I))
     (bvsle #x00000000 (bvadd #xfffffff8 N F))
     (bvsle #x00000000 (bvadd #xfffffff8 L K))
     (bvsle #x00000000 (bvadd #xfffffff8 I G))
     (bvsle #x00000000 (bvadd #xfffffff8 I J))
     (bvsle #x00000000 (bvadd #xfffffff8 F G))
     (bvsle #x00000000 (bvadd #xfffffff8 F J))
     (bvsle #x00000000 (bvadd #xfffffff8 D E))
     (bvsle #x00000000 (bvadd #xfffffff8 D B))
     (bvsle #x00000000 (bvadd #xfffffff8 A I))
     (bvsle #x00000000 (bvadd #xfffffff8 A F))
     (bvsle #x00000000 (bvadd #xfffffffa N G))
     (bvsle #x00000000 (bvadd #xfffffffa N A))
     (bvsle #x00000000 (bvadd #xfffffffa N J))
     (bvsle #x00000000 (bvadd #xfffffffa H I))
     (bvsle #x00000000 (bvadd #xfffffffa H F))
     (bvsle #x00000000 (bvadd #xfffffffa G J))
     (bvsle #x00000000 (bvadd #xfffffffa E L))
     (bvsle #x00000000 (bvadd #xfffffffa E K))
     (bvsle #x00000000 (bvadd #xfffffffa C I))
     (bvsle #x00000000 (bvadd #xfffffffa C F))
     (bvsle #x00000000 (bvadd #xfffffffa B L))
     (bvsle #x00000000 (bvadd #xfffffffa B K))
     (bvsle #x00000000 (bvadd #xfffffffa A G))
     (bvsle #x00000000 (bvadd #xfffffffa A J))
     (bvsle #x00000000 (bvadd #xfffffff9 N L))
     (bvsle #x00000000 (bvadd #xfffffff9 N K))
     (bvsle #x00000000 (bvadd #xfffffff9 L J))
     (bvsle #x00000000 (bvadd #xfffffff9 K J))
     (bvsle #x00000000 (bvadd #xfffffff9 I B))
     (bvsle #x00000000 (bvadd #xfffffff9 G L))
     (bvsle #x00000000 (bvadd #xfffffff9 G K))
     (bvsle #x00000000 (bvadd #xfffffff9 E I))
     (bvsle #x00000000 (bvadd #xfffffff9 E F))
     (bvsle #x00000000 (bvadd #xfffffff9 D H))
     (bvsle #x00000000 (bvadd #xfffffff9 D C))
     (bvsle #x00000000 (bvadd #xfffffff9 B F))
     (bvsle #x00000000 (bvadd #xfffffff9 A L))
     (bvsle #x00000000 (bvadd #xfffffff9 A K))
     (bvsle #x00000000 (bvadd #xfffffffd (bvmul #xffffffff H) L))
     (bvsle #x00000000 (bvadd #xfffffffd (bvmul #xffffffff H) K))
     (bvsle #x00000000 (bvadd #xfffffffd (bvmul #xffffffff E) I))
     (bvsle #x00000000 (bvadd #xfffffffd (bvmul #xffffffff E) F))
     (bvsle #x00000000 (bvadd #xfffffffd (bvmul #xffffffff C) L))
     (bvsle #x00000000 (bvadd #xfffffffd (bvmul #xffffffff C) K))
     (bvsle #x00000000 (bvadd #xfffffffd (bvmul #xffffffff B) F))
     (bvsle #x00000000 (bvadd #xfffffffd I (bvmul #xffffffff B)))
     (bvsle #x00000000 (bvadd #xfffffffd H B))
     (bvsle #x00000000 (bvadd #xfffffffd E H))
     (bvsle #x00000000 (bvadd #xfffffffd E C))
     (bvsle #x00000000 (bvadd #xfffffffd D (bvmul #xffffffff N)))
     (bvsle #x00000000 (bvadd #xfffffffd D (bvmul #xffffffff G)))
     (bvsle #x00000000 (bvadd #xfffffffd D (bvmul #xffffffff A)))
     (bvsle #x00000000 (bvadd #xfffffffd D (bvmul #xffffffff J)))
     (bvsle #x00000000 (bvadd #xfffffffd C B))
     (bvsle #x00000000 (bvadd #xfffffffe (bvmul #xffffffff N) I))
     (bvsle #x00000000 (bvadd #xfffffffe (bvmul #xffffffff N) F))
     (bvsle #x00000000 (bvadd #xfffffffe (bvmul #xffffffff H) G))
     (bvsle #x00000000 (bvadd #xfffffffe (bvmul #xffffffff H) J))
     (bvsle #x00000000 (bvadd #xfffffffe (bvmul #xffffffff E) L))
     (bvsle #x00000000 (bvadd #xfffffffe (bvmul #xffffffff E) K))
     (bvsle #x00000000 (bvadd #xfffffffe (bvmul #xffffffff C) N))
     (bvsle #x00000000 (bvadd #xfffffffe (bvmul #xffffffff C) G))
     (bvsle #x00000000 (bvadd #xfffffffe (bvmul #xffffffff C) A))
     (bvsle #x00000000 (bvadd #xfffffffe (bvmul #xffffffff C) J))
     (bvsle #x00000000 (bvadd #xfffffffe (bvmul #xffffffff B) L))
     (bvsle #x00000000 (bvadd #xfffffffe (bvmul #xffffffff B) K))
     (bvsle #x00000000 (bvadd #xfffffffe (bvmul #xffffffff A) I))
     (bvsle #x00000000 (bvadd #xfffffffe (bvmul #xffffffff A) F))
     (bvsle #x00000000 (bvadd #xfffffffe N (bvmul #xffffffff H)))
     (bvsle #x00000000 (bvadd #xfffffffe I (bvmul #xffffffff G)))
     (bvsle #x00000000 (bvadd #xfffffffe I (bvmul #xffffffff J)))
     (bvsle #x00000000 (bvadd #xfffffffe F (bvmul #xffffffff G)))
     (bvsle #x00000000 (bvadd #xfffffffe F (bvmul #xffffffff J)))
     (bvsle #x00000000 (bvadd #xfffffffe D (bvmul #xffffffff K)))
     (bvsle #x00000000 (bvadd #xfffffffe C H))
     (bvsle #x00000000 (bvadd #xfffffffe A (bvmul #xffffffff H)))
     (bvsle #x00000000 (bvadd #xffffffff (bvmul #xffffffff N) L))
     (bvsle #x00000000 (bvadd #xffffffff (bvmul #xffffffff N) K))
     (bvsle #x00000000 (bvadd #xffffffff (bvmul #xffffffff H) B))
     (bvsle #x00000000 (bvadd #xffffffff (bvmul #xffffffff G) L))
     (bvsle #x00000000 (bvadd #xffffffff (bvmul #xffffffff G) K))
     (bvsle #x00000000 (bvadd #xffffffff (bvmul #xffffffff E) N))
     (bvsle #x00000000 (bvadd #xffffffff (bvmul #xffffffff E) G))
     (bvsle #x00000000 (bvadd #xffffffff (bvmul #xffffffff E) A))
     (bvsle #x00000000 (bvadd #xffffffff (bvmul #xffffffff E) J))
     (bvsle #x00000000 (bvadd #xffffffff (bvmul #xffffffff C) B))
     (bvsle #x00000000 (bvadd #xffffffff (bvmul #xffffffff B) G))
     (bvsle #x00000000 (bvadd #xffffffff (bvmul #xffffffff B) J))
     (bvsle #x00000000 (bvadd #xffffffff (bvmul #xffffffff A) L))
     (bvsle #x00000000 (bvadd #xffffffff (bvmul #xffffffff A) K))
     (bvsle #x00000000 (bvadd #xffffffff N (bvmul #xffffffff B)))
     (bvsle #x00000000 (bvadd #xffffffff L (bvmul #xffffffff J)))
     (bvsle #x00000000 (bvadd #xffffffff K (bvmul #xffffffff J)))
     (bvsle #x00000000 (bvadd #xffffffff I (bvmul #xffffffff K)))
     (bvsle #x00000000 (bvadd #xffffffff F (bvmul #xffffffff K)))
     (bvsle #x00000000 (bvadd #xffffffff E (bvmul #xffffffff H)))
     (bvsle #x00000000 (bvadd #xffffffff E (bvmul #xffffffff C)))
     (bvsle #x00000000 (bvadd #xffffffff D (bvmul #xffffffff L)))
     (bvsle #x00000000 (bvadd #xffffffff D (bvmul #xffffffff I)))
     (bvsle #x00000000 (bvadd #xffffffff D (bvmul #xffffffff F)))
     (bvsle #x00000000 (bvadd #xffffffff A (bvmul #xffffffff B)))
     (bvsle #x00000000 (bvadd #x00000002 (bvmul #xffffffff L) J))
     (bvsle #x00000000
            (bvadd #x00000002 (bvmul #xffffffff C) (bvmul #xffffffff H)))
     (bvsle #x00000000 (bvadd #x00000001 (bvmul #xffffffff N) B))
     (bvsle #x00000000 (bvadd #x00000001 (bvmul #xffffffff L) K))
     (bvsle #x00000000 (bvadd #x00000001 (bvmul #xffffffff K) J))
     (bvsle #x00000000 (bvadd #x00000001 (bvmul #xffffffff D) I))
     (bvsle #x00000000 (bvadd #x00000001 (bvmul #xffffffff D) F))
     (bvsle #x00000000 (bvadd #x00000001 (bvmul #xffffffff A) B))
     (bvsle #x00000000 (bvadd #x00000001 E (bvmul #xffffffff N)))
     (bvsle #x00000000 (bvadd #x00000001 E (bvmul #xffffffff G)))
     (bvsle #x00000000 (bvadd #x00000001 E (bvmul #xffffffff A)))
     (bvsle #x00000000 (bvadd #x00000001 B (bvmul #xffffffff G)))
     (bvsle #x00000000 (bvadd #xfffffffc L))
     (bvsle #x00000000 (bvadd #xfffffffc K))
     (bvsle #x00000000 (bvadd #xfffffffb I))
     (bvsle #x00000000 (bvadd #xfffffffb F))
     (bvsle #x00000000 (bvadd #xfffffffa D))
     (bvsle #x00000000 (bvadd #xfffffffd N))
     (bvsle #x00000000 (bvadd #xfffffffd G))
     (bvsle #x00000000 (bvadd #xfffffffd A))
     (bvsle #x00000000 (bvadd #xfffffffd J))
     (bvsle #x00000000 (bvadd #xfffffffe E))
     (bvsle #x00000000 (bvadd #xfffffffe B))
     (bvsle #x00000000 (bvadd #xffffffff H))
     (bvsle #x00000000 (bvadd #xffffffff C))
     (bvsle #x00000000 (bvadd (bvmul #xffffffff N) G))
     (bvsle #x00000000 (bvadd (bvmul #xffffffff N) A))
     (bvsle #x00000000 (bvadd (bvmul #xffffffff N) J))
     (bvsle #x00000000 (bvadd (bvmul #xffffffff I) F))
     (bvsle #x00000000 (bvadd (bvmul #xffffffff G) J))
     (bvsle #x00000000 (bvadd (bvmul #xffffffff E) B))
     (bvsle #x00000000 (bvadd (bvmul #xffffffff C) H))
     (bvsle #x00000000 (bvadd (bvmul #xffffffff A) G))
     (bvsle #x00000000 (bvadd (bvmul #xffffffff A) J))
     (bvsle #x00000000 (bvadd #x00000001 (bvmul #xffffffff H)))
     (bvsle #x00000000 (bvadd #x00000001 (bvmul #xffffffff C)))
     (bvsle #x00000000 (bvadd N (bvmul #xffffffff G)))
     (bvsle #x00000000 (bvadd N (bvmul #xffffffff A)))
     (bvsle #x00000000 (bvadd L (bvmul #xffffffff K)))
     (bvsle #x00000000 (bvadd I (bvmul #xffffffff L)))
     (bvsle #x00000000 (bvadd I (bvmul #xffffffff F)))
     (bvsle #x00000000 (bvadd F (bvmul #xffffffff L)))
     (bvsle #x00000000 (bvadd E (bvmul #xffffffff B)))
     (bvsle #x00000000 (bvadd C (bvmul #xffffffff H)))
     (bvsle #x00000000 (bvadd A (bvmul #xffffffff G)))
     (bvsle #x00000000 (bvadd #xfffffff5 D I)))
      )
      (lturn N A B C D E F G H I J K L M)
    )
  )
)
(assert
  (forall ( (A (_ BitVec 32)) (B (_ BitVec 32)) (C (_ BitVec 32)) (D (_ BitVec 32)) (E (_ BitVec 32)) (F (_ BitVec 32)) (G (_ BitVec 32)) (H (_ BitVec 32)) (I (_ BitVec 32)) (J (_ BitVec 32)) (K (_ BitVec 32)) (L (_ BitVec 32)) (M (_ BitVec 32)) (N (_ BitVec 32)) ) 
    (=>
      (and
        (and (bvsle #x00000000 (bvadd #xfffffff5 D F))
     (bvsle #x00000000 (bvadd #xfffffff6 I F))
     (bvsle #x00000000 (bvadd #xfffffff7 D N))
     (bvsle #x00000000 (bvadd #xfffffff7 D G))
     (bvsle #x00000000 (bvadd #xfffffff7 D A))
     (bvsle #x00000000 (bvadd #xfffffff7 D J))
     (bvsle #x00000000 (bvadd #xfffffffc (bvmul #xffffffff H) I))
     (bvsle #x00000000 (bvadd #xfffffffc (bvmul #xffffffff H) F))
     (bvsle #x00000000 (bvadd #xfffffffc (bvmul #xffffffff C) I))
     (bvsle #x00000000 (bvadd #xfffffffc (bvmul #xffffffff C) F))
     (bvsle #x00000000 (bvadd #xfffffffc N L))
     (bvsle #x00000000 (bvadd #xfffffffc N H))
     (bvsle #x00000000 (bvadd #xfffffffc L J))
     (bvsle #x00000000 (bvadd #xfffffffc H G))
     (bvsle #x00000000 (bvadd #xfffffffc H J))
     (bvsle #x00000000 (bvadd #xfffffffc G L))
     (bvsle #x00000000 (bvadd #xfffffffc E K))
     (bvsle #x00000000 (bvadd #xfffffffc E B))
     (bvsle #x00000000 (bvadd #xfffffffc D (bvmul #xffffffff E)))
     (bvsle #x00000000 (bvadd #xfffffffc D (bvmul #xffffffff B)))
     (bvsle #x00000000 (bvadd #xfffffffc C N))
     (bvsle #x00000000 (bvadd #xfffffffc C G))
     (bvsle #x00000000 (bvadd #xfffffffc C A))
     (bvsle #x00000000 (bvadd #xfffffffc C J))
     (bvsle #x00000000 (bvadd #xfffffffc B K))
     (bvsle #x00000000 (bvadd #xfffffffc A L))
     (bvsle #x00000000 (bvadd #xfffffffc A H))
     (bvsle #x00000000 (bvadd #xfffffffb N K))
     (bvsle #x00000000 (bvadd #xfffffffb N B))
     (bvsle #x00000000 (bvadd #xfffffffb K J))
     (bvsle #x00000000 (bvadd #xfffffffb G K))
     (bvsle #x00000000 (bvadd #xfffffffb E N))
     (bvsle #x00000000 (bvadd #xfffffffb E G))
     (bvsle #x00000000 (bvadd #xfffffffb E A))
     (bvsle #x00000000 (bvadd #xfffffffb E J))
     (bvsle #x00000000 (bvadd #xfffffffb D (bvmul #xffffffff H)))
     (bvsle #x00000000 (bvadd #xfffffffb D (bvmul #xffffffff C)))
     (bvsle #x00000000 (bvadd #xfffffffb B G))
     (bvsle #x00000000 (bvadd #xfffffffb B J))
     (bvsle #x00000000 (bvadd #xfffffffb A K))
     (bvsle #x00000000 (bvadd #xfffffffb A B))
     (bvsle #x00000000 (bvadd #xfffffff8 N I))
     (bvsle #x00000000 (bvadd #xfffffff8 N F))
     (bvsle #x00000000 (bvadd #xfffffff8 I G))
     (bvsle #x00000000 (bvadd #xfffffff8 I J))
     (bvsle #x00000000 (bvadd #xfffffff8 F G))
     (bvsle #x00000000 (bvadd #xfffffff8 F J))
     (bvsle #x00000000 (bvadd #xfffffff8 D K))
     (bvsle #x00000000 (bvadd #xfffffff8 D E))
     (bvsle #x00000000 (bvadd #xfffffff8 D B))
     (bvsle #x00000000 (bvadd #xfffffff8 A I))
     (bvsle #x00000000 (bvadd #xfffffff8 A F))
     (bvsle #x00000000 (bvadd #xfffffffa N G))
     (bvsle #x00000000 (bvadd #xfffffffa N A))
     (bvsle #x00000000 (bvadd #xfffffffa N J))
     (bvsle #x00000000 (bvadd #xfffffffa I L))
     (bvsle #x00000000 (bvadd #xfffffffa H I))
     (bvsle #x00000000 (bvadd #xfffffffa H F))
     (bvsle #x00000000 (bvadd #xfffffffa G J))
     (bvsle #x00000000 (bvadd #xfffffffa F L))
     (bvsle #x00000000 (bvadd #xfffffffa C I))
     (bvsle #x00000000 (bvadd #xfffffffa C F))
     (bvsle #x00000000 (bvadd #xfffffffa A G))
     (bvsle #x00000000 (bvadd #xfffffffa A J))
     (bvsle #x00000000 (bvadd #xfffffff9 I K))
     (bvsle #x00000000 (bvadd #xfffffff9 I B))
     (bvsle #x00000000 (bvadd #xfffffff9 F K))
     (bvsle #x00000000 (bvadd #xfffffff9 E I))
     (bvsle #x00000000 (bvadd #xfffffff9 E F))
     (bvsle #x00000000 (bvadd #xfffffff9 D L))
     (bvsle #x00000000 (bvadd #xfffffff9 D H))
     (bvsle #x00000000 (bvadd #xfffffff9 D C))
     (bvsle #x00000000 (bvadd #xfffffff9 B F))
     (bvsle #x00000000 (bvadd #xfffffffd (bvmul #xffffffff E) I))
     (bvsle #x00000000 (bvadd #xfffffffd (bvmul #xffffffff E) F))
     (bvsle #x00000000 (bvadd #xfffffffd (bvmul #xffffffff B) F))
     (bvsle #x00000000 (bvadd #xfffffffd L K))
     (bvsle #x00000000 (bvadd #xfffffffd I (bvmul #xffffffff B)))
     (bvsle #x00000000 (bvadd #xfffffffd H K))
     (bvsle #x00000000 (bvadd #xfffffffd H B))
     (bvsle #x00000000 (bvadd #xfffffffd E L))
     (bvsle #x00000000 (bvadd #xfffffffd E H))
     (bvsle #x00000000 (bvadd #xfffffffd E C))
     (bvsle #x00000000 (bvadd #xfffffffd D (bvmul #xffffffff G)))
     (bvsle #x00000000 (bvadd #xfffffffd D (bvmul #xffffffff A)))
     (bvsle #x00000000 (bvadd #xfffffffd C K))
     (bvsle #x00000000 (bvadd #xfffffffd C B))
     (bvsle #x00000000 (bvadd #xfffffffd B L))
     (bvsle #x00000000 (bvadd #xfffffffe (bvmul #xffffffff H) G))
     (bvsle #x00000000 (bvadd #xfffffffe (bvmul #xffffffff H) J))
     (bvsle #x00000000 (bvadd #xfffffffe (bvmul #xffffffff C) N))
     (bvsle #x00000000 (bvadd #xfffffffe (bvmul #xffffffff C) G))
     (bvsle #x00000000 (bvadd #xfffffffe (bvmul #xffffffff C) A))
     (bvsle #x00000000 (bvadd #xfffffffe (bvmul #xffffffff C) J))
     (bvsle #x00000000 (bvadd #xfffffffe (bvmul #xffffffff A) I))
     (bvsle #x00000000 (bvadd #xfffffffe (bvmul #xffffffff A) F))
     (bvsle #x00000000 (bvadd #xfffffffe N (bvmul #xffffffff H)))
     (bvsle #x00000000 (bvadd #xfffffffe I (bvmul #xffffffff G)))
     (bvsle #x00000000 (bvadd #xfffffffe H L))
     (bvsle #x00000000 (bvadd #xfffffffe F (bvmul #xffffffff G)))
     (bvsle #x00000000 (bvadd #xfffffffe D (bvmul #xffffffff N)))
     (bvsle #x00000000 (bvadd #xfffffffe D (bvmul #xffffffff L)))
     (bvsle #x00000000 (bvadd #xfffffffe C L))
     (bvsle #x00000000 (bvadd #xfffffffe C H))
     (bvsle #x00000000 (bvadd #xfffffffe A (bvmul #xffffffff H)))
     (bvsle #x00000000 (bvadd #xffffffff (bvmul #xffffffff N) I))
     (bvsle #x00000000 (bvadd #xffffffff (bvmul #xffffffff N) F))
     (bvsle #x00000000 (bvadd #xffffffff (bvmul #xffffffff L) J))
     (bvsle #x00000000 (bvadd #xffffffff (bvmul #xffffffff H) K))
     (bvsle #x00000000 (bvadd #xffffffff (bvmul #xffffffff H) B))
     (bvsle #x00000000 (bvadd #xffffffff (bvmul #xffffffff E) N))
     (bvsle #x00000000 (bvadd #xffffffff (bvmul #xffffffff E) G))
     (bvsle #x00000000 (bvadd #xffffffff (bvmul #xffffffff E) A))
     (bvsle #x00000000 (bvadd #xffffffff (bvmul #xffffffff C) K))
     (bvsle #x00000000 (bvadd #xffffffff (bvmul #xffffffff C) B))
     (bvsle #x00000000 (bvadd #xffffffff (bvmul #xffffffff B) G))
     (bvsle #x00000000 (bvadd #xffffffff N (bvmul #xffffffff B)))
     (bvsle #x00000000 (bvadd #xffffffff I (bvmul #xffffffff L)))
     (bvsle #x00000000 (bvadd #xffffffff F (bvmul #xffffffff L)))
     (bvsle #x00000000 (bvadd #xffffffff E (bvmul #xffffffff H)))
     (bvsle #x00000000 (bvadd #xffffffff E (bvmul #xffffffff C)))
     (bvsle #x00000000 (bvadd #xffffffff D (bvmul #xffffffff K)))
     (bvsle #x00000000 (bvadd #xffffffff D (bvmul #xffffffff I)))
     (bvsle #x00000000 (bvadd #xffffffff D (bvmul #xffffffff F)))
     (bvsle #x00000000 (bvadd #xffffffff D (bvmul #xffffffff J)))
     (bvsle #x00000000 (bvadd #xffffffff A (bvmul #xffffffff B)))
     (bvsle #x00000000 (bvadd #x00000002 (bvmul #xffffffff N) B))
     (bvsle #x00000000
            (bvadd #x00000002 (bvmul #xffffffff C) (bvmul #xffffffff H)))
     (bvsle #x00000000 (bvadd #x00000002 E (bvmul #xffffffff N)))
     (bvsle #x00000000 (bvadd #x00000001 (bvmul #xffffffff N) G))
     (bvsle #x00000000 (bvadd #x00000001 (bvmul #xffffffff N) A))
     (bvsle #x00000000 (bvadd #x00000001 (bvmul #xffffffff D) I))
     (bvsle #x00000000 (bvadd #x00000001 (bvmul #xffffffff D) F))
     (bvsle #x00000000 (bvadd #x00000001 (bvmul #xffffffff A) B))
     (bvsle #x00000000 (bvadd #x00000001 E (bvmul #xffffffff G)))
     (bvsle #x00000000 (bvadd #x00000001 E (bvmul #xffffffff A)))
     (bvsle #x00000000 (bvadd #x00000001 B (bvmul #xffffffff G)))
     (bvsle #x00000000 (bvadd #xfffffffb I))
     (bvsle #x00000000 (bvadd #xfffffffb F))
     (bvsle #x00000000 (bvadd #xfffffffa D))
     (bvsle #x00000000 (bvadd #xfffffffd N))
     (bvsle #x00000000 (bvadd #xfffffffd G))
     (bvsle #x00000000 (bvadd #xfffffffd A))
     (bvsle #x00000000 (bvadd #xfffffffd J))
     (bvsle #x00000000 (bvadd #xfffffffe K))
     (bvsle #x00000000 (bvadd #xfffffffe E))
     (bvsle #x00000000 (bvadd #xfffffffe B))
     (bvsle #x00000000 (bvadd #xffffffff L))
     (bvsle #x00000000 (bvadd #xffffffff H))
     (bvsle #x00000000 (bvadd #xffffffff C))
     (bvsle #x00000000 (bvadd (bvmul #xffffffff K) J))
     (bvsle #x00000000 (bvadd (bvmul #xffffffff I) F))
     (bvsle #x00000000 (bvadd (bvmul #xffffffff H) L))
     (bvsle #x00000000 (bvadd (bvmul #xffffffff E) B))
     (bvsle #x00000000 (bvadd (bvmul #xffffffff C) L))
     (bvsle #x00000000 (bvadd (bvmul #xffffffff C) H))
     (bvsle #x00000000 (bvadd (bvmul #xffffffff A) G))
     (bvsle #x00000000 (bvadd #x00000001 (bvmul #xffffffff H)))
     (bvsle #x00000000 (bvadd #x00000001 (bvmul #xffffffff C)))
     (bvsle #x00000000 (bvadd N (bvmul #xffffffff G)))
     (bvsle #x00000000 (bvadd N (bvmul #xffffffff A)))
     (bvsle #x00000000 (bvadd I (bvmul #xffffffff K)))
     (bvsle #x00000000 (bvadd I (bvmul #xffffffff F)))
     (bvsle #x00000000 (bvadd I (bvmul #xffffffff J)))
     (bvsle #x00000000 (bvadd F (bvmul #xffffffff K)))
     (bvsle #x00000000 (bvadd F (bvmul #xffffffff J)))
     (bvsle #x00000000 (bvadd E (bvmul #xffffffff B)))
     (bvsle #x00000000 (bvadd C (bvmul #xffffffff H)))
     (bvsle #x00000000 (bvadd A (bvmul #xffffffff G)))
     (bvsle #x00000000 (bvadd #xfffffff5 D I)))
      )
      (lturn N A B C D E F G H I J K L M)
    )
  )
)
(assert
  (forall ( (A (_ BitVec 32)) (B (_ BitVec 32)) (C (_ BitVec 32)) (D (_ BitVec 32)) (E (_ BitVec 32)) (F (_ BitVec 32)) (G (_ BitVec 32)) (H (_ BitVec 32)) (I (_ BitVec 32)) (J (_ BitVec 32)) (K (_ BitVec 32)) (L (_ BitVec 32)) (M (_ BitVec 32)) (N (_ BitVec 32)) ) 
    (=>
      (and
        (and (bvsle #x00000000 (bvadd #xfffffff7 D I))
     (bvsle #x00000000 (bvadd #xfffffff7 D F))
     (bvsle #x00000000 (bvadd #xfffffffc L J))
     (bvsle #x00000000 (bvadd #xfffffffc H G))
     (bvsle #x00000000 (bvadd #xfffffffc H J))
     (bvsle #x00000000 (bvadd #xfffffffc G L))
     (bvsle #x00000000 (bvadd #xfffffffc E K))
     (bvsle #x00000000 (bvadd #xfffffffc E B))
     (bvsle #x00000000 (bvadd #xfffffffc D (bvmul #xffffffff H)))
     (bvsle #x00000000 (bvadd #xfffffffc D (bvmul #xffffffff C)))
     (bvsle #x00000000 (bvadd #xfffffffc C G))
     (bvsle #x00000000 (bvadd #xfffffffc C A))
     (bvsle #x00000000 (bvadd #xfffffffc C J))
     (bvsle #x00000000 (bvadd #xfffffffc B K))
     (bvsle #x00000000 (bvadd #xfffffffc A L))
     (bvsle #x00000000 (bvadd #xfffffffc A H))
     (bvsle #x00000000 (bvadd #xfffffffb N L))
     (bvsle #x00000000 (bvadd #xfffffffb N H))
     (bvsle #x00000000 (bvadd #xfffffffb K J))
     (bvsle #x00000000 (bvadd #xfffffffb I L))
     (bvsle #x00000000 (bvadd #xfffffffb H I))
     (bvsle #x00000000 (bvadd #xfffffffb H F))
     (bvsle #x00000000 (bvadd #xfffffffb G K))
     (bvsle #x00000000 (bvadd #xfffffffb F L))
     (bvsle #x00000000 (bvadd #xfffffffb E G))
     (bvsle #x00000000 (bvadd #xfffffffb E A))
     (bvsle #x00000000 (bvadd #xfffffffb E J))
     (bvsle #x00000000 (bvadd #xfffffffb C N))
     (bvsle #x00000000 (bvadd #xfffffffb C I))
     (bvsle #x00000000 (bvadd #xfffffffb C F))
     (bvsle #x00000000 (bvadd #xfffffffb B G))
     (bvsle #x00000000 (bvadd #xfffffffb B J))
     (bvsle #x00000000 (bvadd #xfffffffb A K))
     (bvsle #x00000000 (bvadd #xfffffffb A B))
     (bvsle #x00000000 (bvadd #xfffffff8 N I))
     (bvsle #x00000000 (bvadd #xfffffff8 N F))
     (bvsle #x00000000 (bvadd #xfffffff8 I F))
     (bvsle #x00000000 (bvadd #xfffffff8 D G))
     (bvsle #x00000000 (bvadd #xfffffff8 D A))
     (bvsle #x00000000 (bvadd #xfffffff8 D J))
     (bvsle #x00000000 (bvadd #xfffffffa N K))
     (bvsle #x00000000 (bvadd #xfffffffa N B))
     (bvsle #x00000000 (bvadd #xfffffffa I K))
     (bvsle #x00000000 (bvadd #xfffffffa I B))
     (bvsle #x00000000 (bvadd #xfffffffa G J))
     (bvsle #x00000000 (bvadd #xfffffffa F K))
     (bvsle #x00000000 (bvadd #xfffffffa E N))
     (bvsle #x00000000 (bvadd #xfffffffa E I))
     (bvsle #x00000000 (bvadd #xfffffffa E F))
     (bvsle #x00000000 (bvadd #xfffffffa D L))
     (bvsle #x00000000 (bvadd #xfffffffa D H))
     (bvsle #x00000000 (bvadd #xfffffffa D C))
     (bvsle #x00000000 (bvadd #xfffffffa B F))
     (bvsle #x00000000 (bvadd #xfffffffa A G))
     (bvsle #x00000000 (bvadd #xfffffffa A J))
     (bvsle #x00000000 (bvadd #xfffffff9 N G))
     (bvsle #x00000000 (bvadd #xfffffff9 N A))
     (bvsle #x00000000 (bvadd #xfffffff9 N J))
     (bvsle #x00000000 (bvadd #xfffffff9 I G))
     (bvsle #x00000000 (bvadd #xfffffff9 I J))
     (bvsle #x00000000 (bvadd #xfffffff9 F G))
     (bvsle #x00000000 (bvadd #xfffffff9 F J))
     (bvsle #x00000000 (bvadd #xfffffff9 D K))
     (bvsle #x00000000 (bvadd #xfffffff9 D E))
     (bvsle #x00000000 (bvadd #xfffffff9 D B))
     (bvsle #x00000000 (bvadd #xfffffff9 A I))
     (bvsle #x00000000 (bvadd #xfffffff9 A F))
     (bvsle #x00000000 (bvadd #xfffffffd (bvmul #xffffffff H) I))
     (bvsle #x00000000 (bvadd #xfffffffd (bvmul #xffffffff H) F))
     (bvsle #x00000000 (bvadd #xfffffffd (bvmul #xffffffff C) N))
     (bvsle #x00000000 (bvadd #xfffffffd (bvmul #xffffffff C) I))
     (bvsle #x00000000 (bvadd #xfffffffd (bvmul #xffffffff C) F))
     (bvsle #x00000000 (bvadd #xfffffffd N (bvmul #xffffffff H)))
     (bvsle #x00000000 (bvadd #xfffffffd L K))
     (bvsle #x00000000 (bvadd #xfffffffd H K))
     (bvsle #x00000000 (bvadd #xfffffffd H B))
     (bvsle #x00000000 (bvadd #xfffffffd E L))
     (bvsle #x00000000 (bvadd #xfffffffd E H))
     (bvsle #x00000000 (bvadd #xfffffffd E C))
     (bvsle #x00000000 (bvadd #xfffffffd D (bvmul #xffffffff E)))
     (bvsle #x00000000 (bvadd #xfffffffd D (bvmul #xffffffff B)))
     (bvsle #x00000000 (bvadd #xfffffffd C K))
     (bvsle #x00000000 (bvadd #xfffffffd C B))
     (bvsle #x00000000 (bvadd #xfffffffd B L))
     (bvsle #x00000000 (bvadd #xfffffffe (bvmul #xffffffff H) G))
     (bvsle #x00000000 (bvadd #xfffffffe (bvmul #xffffffff H) J))
     (bvsle #x00000000 (bvadd #xfffffffe (bvmul #xffffffff E) N))
     (bvsle #x00000000 (bvadd #xfffffffe (bvmul #xffffffff E) I))
     (bvsle #x00000000 (bvadd #xfffffffe (bvmul #xffffffff E) F))
     (bvsle #x00000000 (bvadd #xfffffffe (bvmul #xffffffff C) G))
     (bvsle #x00000000 (bvadd #xfffffffe (bvmul #xffffffff C) A))
     (bvsle #x00000000 (bvadd #xfffffffe (bvmul #xffffffff C) J))
     (bvsle #x00000000 (bvadd #xfffffffe (bvmul #xffffffff B) F))
     (bvsle #x00000000 (bvadd #xfffffffe N (bvmul #xffffffff B)))
     (bvsle #x00000000 (bvadd #xfffffffe I (bvmul #xffffffff B)))
     (bvsle #x00000000 (bvadd #xfffffffe H L))
     (bvsle #x00000000 (bvadd #xfffffffe D (bvmul #xffffffff L)))
     (bvsle #x00000000 (bvadd #xfffffffe D (bvmul #xffffffff G)))
     (bvsle #x00000000 (bvadd #xfffffffe D (bvmul #xffffffff A)))
     (bvsle #x00000000 (bvadd #xfffffffe C L))
     (bvsle #x00000000 (bvadd #xfffffffe C H))
     (bvsle #x00000000 (bvadd #xfffffffe A (bvmul #xffffffff H)))
     (bvsle #x00000000 (bvadd #xffffffff (bvmul #xffffffff L) J))
     (bvsle #x00000000 (bvadd #xffffffff (bvmul #xffffffff H) K))
     (bvsle #x00000000 (bvadd #xffffffff (bvmul #xffffffff H) B))
     (bvsle #x00000000 (bvadd #xffffffff (bvmul #xffffffff E) G))
     (bvsle #x00000000 (bvadd #xffffffff (bvmul #xffffffff E) A))
     (bvsle #x00000000 (bvadd #xffffffff (bvmul #xffffffff C) K))
     (bvsle #x00000000 (bvadd #xffffffff (bvmul #xffffffff C) B))
     (bvsle #x00000000 (bvadd #xffffffff (bvmul #xffffffff B) G))
     (bvsle #x00000000 (bvadd #xffffffff (bvmul #xffffffff A) I))
     (bvsle #x00000000 (bvadd #xffffffff (bvmul #xffffffff A) F))
     (bvsle #x00000000 (bvadd #xffffffff N (bvmul #xffffffff L)))
     (bvsle #x00000000 (bvadd #xffffffff N (bvmul #xffffffff G)))
     (bvsle #x00000000 (bvadd #xffffffff N (bvmul #xffffffff A)))
     (bvsle #x00000000 (bvadd #xffffffff I (bvmul #xffffffff L)))
     (bvsle #x00000000 (bvadd #xffffffff I (bvmul #xffffffff G)))
     (bvsle #x00000000 (bvadd #xffffffff F (bvmul #xffffffff L)))
     (bvsle #x00000000 (bvadd #xffffffff F (bvmul #xffffffff G)))
     (bvsle #x00000000 (bvadd #xffffffff E (bvmul #xffffffff H)))
     (bvsle #x00000000 (bvadd #xffffffff E (bvmul #xffffffff C)))
     (bvsle #x00000000 (bvadd #xffffffff D (bvmul #xffffffff N)))
     (bvsle #x00000000 (bvadd #xffffffff D (bvmul #xffffffff K)))
     (bvsle #x00000000 (bvadd #xffffffff D (bvmul #xffffffff I)))
     (bvsle #x00000000 (bvadd #xffffffff D (bvmul #xffffffff F)))
     (bvsle #x00000000 (bvadd #xffffffff D (bvmul #xffffffff J)))
     (bvsle #x00000000 (bvadd #xffffffff A (bvmul #xffffffff B)))
     (bvsle #x00000000 (bvadd #x00000003 (bvmul #xffffffff D) E))
     (bvsle #x00000000 (bvadd #x00000003 (bvmul #xffffffff D) B))
     (bvsle #x00000000 (bvadd #x00000002 (bvmul #xffffffff N) B))
     (bvsle #x00000000 (bvadd #x00000002 (bvmul #xffffffff I) B))
     (bvsle #x00000000 (bvadd #x00000002 (bvmul #xffffffff D) G))
     (bvsle #x00000000 (bvadd #x00000002 (bvmul #xffffffff D) A))
     (bvsle #x00000000
            (bvadd #x00000002 (bvmul #xffffffff C) (bvmul #xffffffff H)))
     (bvsle #x00000000 (bvadd #x00000002 E (bvmul #xffffffff N)))
     (bvsle #x00000000 (bvadd #x00000002 E (bvmul #xffffffff K)))
     (bvsle #x00000000 (bvadd #x00000002 E (bvmul #xffffffff I)))
     (bvsle #x00000000 (bvadd #x00000002 E (bvmul #xffffffff F)))
     (bvsle #x00000000 (bvadd #x00000002 E (bvmul #xffffffff J)))
     (bvsle #x00000000 (bvadd #x00000002 B (bvmul #xffffffff K)))
     (bvsle #x00000000 (bvadd #x00000002 B (bvmul #xffffffff F)))
     (bvsle #x00000000 (bvadd #x00000002 B (bvmul #xffffffff J)))
     (bvsle #x00000000 (bvadd #x00000001 (bvmul #xffffffff N) G))
     (bvsle #x00000000 (bvadd #x00000001 (bvmul #xffffffff N) A))
     (bvsle #x00000000 (bvadd #x00000001 (bvmul #xffffffff I) G))
     (bvsle #x00000000 (bvadd #x00000001 (bvmul #xffffffff F) G))
     (bvsle #x00000000 (bvadd #x00000001 (bvmul #xffffffff D) N))
     (bvsle #x00000000 (bvadd #x00000001 (bvmul #xffffffff D) I))
     (bvsle #x00000000 (bvadd #x00000001 (bvmul #xffffffff D) F))
     (bvsle #x00000000 (bvadd #x00000001 (bvmul #xffffffff A) B))
     (bvsle #x00000000 (bvadd #x00000001 G (bvmul #xffffffff K)))
     (bvsle #x00000000 (bvadd #x00000001 G (bvmul #xffffffff J)))
     (bvsle #x00000000 (bvadd #x00000001 E (bvmul #xffffffff L)))
     (bvsle #x00000000 (bvadd #x00000001 E (bvmul #xffffffff G)))
     (bvsle #x00000000 (bvadd #x00000001 E (bvmul #xffffffff A)))
     (bvsle #x00000000 (bvadd #x00000001 B (bvmul #xffffffff L)))
     (bvsle #x00000000 (bvadd #x00000001 B (bvmul #xffffffff G)))
     (bvsle #x00000000 (bvadd #x00000001 A (bvmul #xffffffff K)))
     (bvsle #x00000000 (bvadd #x00000001 A (bvmul #xffffffff I)))
     (bvsle #x00000000 (bvadd #x00000001 A (bvmul #xffffffff F)))
     (bvsle #x00000000 (bvadd #x00000001 A (bvmul #xffffffff J)))
     (bvsle #x00000000 (bvadd #xfffffffc N))
     (bvsle #x00000000 (bvadd #xfffffffc I))
     (bvsle #x00000000 (bvadd #xfffffffc F))
     (bvsle #x00000000 (bvadd #xfffffffb D))
     (bvsle #x00000000 (bvadd #xfffffffd G))
     (bvsle #x00000000 (bvadd #xfffffffd A))
     (bvsle #x00000000 (bvadd #xfffffffd J))
     (bvsle #x00000000 (bvadd #xfffffffe K))
     (bvsle #x00000000 (bvadd #xfffffffe E))
     (bvsle #x00000000 (bvadd #xfffffffe B))
     (bvsle #x00000000 (bvadd #xffffffff L))
     (bvsle #x00000000 (bvadd #xffffffff H))
     (bvsle #x00000000 (bvadd #xffffffff C))
     (bvsle #x00000000 (bvadd (bvmul #xffffffff N) I))
     (bvsle #x00000000 (bvadd (bvmul #xffffffff N) F))
     (bvsle #x00000000 (bvadd (bvmul #xffffffff K) J))
     (bvsle #x00000000 (bvadd (bvmul #xffffffff I) F))
     (bvsle #x00000000 (bvadd (bvmul #xffffffff H) L))
     (bvsle #x00000000 (bvadd (bvmul #xffffffff E) B))
     (bvsle #x00000000 (bvadd (bvmul #xffffffff C) L))
     (bvsle #x00000000 (bvadd (bvmul #xffffffff C) H))
     (bvsle #x00000000 (bvadd (bvmul #xffffffff A) G))
     (bvsle #x00000000 (bvadd #x00000001 (bvmul #xffffffff H)))
     (bvsle #x00000000 (bvadd #x00000001 (bvmul #xffffffff C)))
     (bvsle #x00000000 (bvadd N (bvmul #xffffffff K)))
     (bvsle #x00000000 (bvadd N (bvmul #xffffffff I)))
     (bvsle #x00000000 (bvadd N (bvmul #xffffffff F)))
     (bvsle #x00000000 (bvadd N (bvmul #xffffffff J)))
     (bvsle #x00000000 (bvadd I (bvmul #xffffffff K)))
     (bvsle #x00000000 (bvadd I (bvmul #xffffffff F)))
     (bvsle #x00000000 (bvadd I (bvmul #xffffffff J)))
     (bvsle #x00000000 (bvadd G (bvmul #xffffffff L)))
     (bvsle #x00000000 (bvadd F (bvmul #xffffffff K)))
     (bvsle #x00000000 (bvadd F (bvmul #xffffffff J)))
     (bvsle #x00000000 (bvadd E (bvmul #xffffffff B)))
     (bvsle #x00000000 (bvadd C (bvmul #xffffffff H)))
     (bvsle #x00000000 (bvadd A (bvmul #xffffffff L)))
     (bvsle #x00000000 (bvadd A (bvmul #xffffffff G)))
     (bvsle #x00000000 (bvadd #xfffffff7 D N)))
      )
      (lturn N A B C D E F G H I J K L M)
    )
  )
)
(assert
  (forall ( (A (_ BitVec 32)) (B (_ BitVec 32)) (C (_ BitVec 32)) (D (_ BitVec 32)) (E (_ BitVec 32)) (F (_ BitVec 32)) (G (_ BitVec 32)) (H (_ BitVec 32)) (I (_ BitVec 32)) (J (_ BitVec 32)) (K (_ BitVec 32)) (L (_ BitVec 32)) (M (_ BitVec 32)) (N (_ BitVec 32)) ) 
    (=>
      (and
        (and (bvsle #x00000000 (bvadd #xfffffff7 D F))
     (bvsle #x00000000 (bvadd #xfffffffc N H))
     (bvsle #x00000000 (bvadd #xfffffffc H L))
     (bvsle #x00000000 (bvadd #xfffffffc H K))
     (bvsle #x00000000 (bvadd #xfffffffc H G))
     (bvsle #x00000000 (bvadd #xfffffffc E B))
     (bvsle #x00000000 (bvadd #xfffffffc E J))
     (bvsle #x00000000 (bvadd #xfffffffc D (bvmul #xffffffff H)))
     (bvsle #x00000000 (bvadd #xfffffffc D (bvmul #xffffffff C)))
     (bvsle #x00000000 (bvadd #xfffffffc C N))
     (bvsle #x00000000 (bvadd #xfffffffc C L))
     (bvsle #x00000000 (bvadd #xfffffffc C K))
     (bvsle #x00000000 (bvadd #xfffffffc C G))
     (bvsle #x00000000 (bvadd #xfffffffc C A))
     (bvsle #x00000000 (bvadd #xfffffffc B J))
     (bvsle #x00000000 (bvadd #xfffffffc A H))
     (bvsle #x00000000 (bvadd #xfffffffb N B))
     (bvsle #x00000000 (bvadd #xfffffffb N J))
     (bvsle #x00000000 (bvadd #xfffffffb L J))
     (bvsle #x00000000 (bvadd #xfffffffb K J))
     (bvsle #x00000000 (bvadd #xfffffffb H I))
     (bvsle #x00000000 (bvadd #xfffffffb H F))
     (bvsle #x00000000 (bvadd #xfffffffb G J))
     (bvsle #x00000000 (bvadd #xfffffffb E N))
     (bvsle #x00000000 (bvadd #xfffffffb E L))
     (bvsle #x00000000 (bvadd #xfffffffb E K))
     (bvsle #x00000000 (bvadd #xfffffffb E G))
     (bvsle #x00000000 (bvadd #xfffffffb E A))
     (bvsle #x00000000 (bvadd #xfffffffb C I))
     (bvsle #x00000000 (bvadd #xfffffffb C F))
     (bvsle #x00000000 (bvadd #xfffffffb B L))
     (bvsle #x00000000 (bvadd #xfffffffb B K))
     (bvsle #x00000000 (bvadd #xfffffffb B G))
     (bvsle #x00000000 (bvadd #xfffffffb A B))
     (bvsle #x00000000 (bvadd #xfffffffb A J))
     (bvsle #x00000000 (bvadd #xfffffff8 I F))
     (bvsle #x00000000 (bvadd #xfffffff8 D N))
     (bvsle #x00000000 (bvadd #xfffffff8 D L))
     (bvsle #x00000000 (bvadd #xfffffff8 D K))
     (bvsle #x00000000 (bvadd #xfffffff8 D G))
     (bvsle #x00000000 (bvadd #xfffffff8 D A))
     (bvsle #x00000000 (bvadd #xfffffffa N L))
     (bvsle #x00000000 (bvadd #xfffffffa N K))
     (bvsle #x00000000 (bvadd #xfffffffa N G))
     (bvsle #x00000000 (bvadd #xfffffffa N A))
     (bvsle #x00000000 (bvadd #xfffffffa L K))
     (bvsle #x00000000 (bvadd #xfffffffa I B))
     (bvsle #x00000000 (bvadd #xfffffffa I J))
     (bvsle #x00000000 (bvadd #xfffffffa G L))
     (bvsle #x00000000 (bvadd #xfffffffa G K))
     (bvsle #x00000000 (bvadd #xfffffffa F J))
     (bvsle #x00000000 (bvadd #xfffffffa E I))
     (bvsle #x00000000 (bvadd #xfffffffa E F))
     (bvsle #x00000000 (bvadd #xfffffffa D H))
     (bvsle #x00000000 (bvadd #xfffffffa D C))
     (bvsle #x00000000 (bvadd #xfffffffa B F))
     (bvsle #x00000000 (bvadd #xfffffffa A L))
     (bvsle #x00000000 (bvadd #xfffffffa A K))
     (bvsle #x00000000 (bvadd #xfffffffa A G))
     (bvsle #x00000000 (bvadd #xfffffff9 N I))
     (bvsle #x00000000 (bvadd #xfffffff9 N F))
     (bvsle #x00000000 (bvadd #xfffffff9 I L))
     (bvsle #x00000000 (bvadd #xfffffff9 I K))
     (bvsle #x00000000 (bvadd #xfffffff9 I G))
     (bvsle #x00000000 (bvadd #xfffffff9 F L))
     (bvsle #x00000000 (bvadd #xfffffff9 F K))
     (bvsle #x00000000 (bvadd #xfffffff9 F G))
     (bvsle #x00000000 (bvadd #xfffffff9 D E))
     (bvsle #x00000000 (bvadd #xfffffff9 D B))
     (bvsle #x00000000 (bvadd #xfffffff9 D J))
     (bvsle #x00000000 (bvadd #xfffffff9 A I))
     (bvsle #x00000000 (bvadd #xfffffff9 A F))
     (bvsle #x00000000 (bvadd #xfffffffd (bvmul #xffffffff H) I))
     (bvsle #x00000000 (bvadd #xfffffffd (bvmul #xffffffff H) F))
     (bvsle #x00000000 (bvadd #xfffffffd (bvmul #xffffffff C) I))
     (bvsle #x00000000 (bvadd #xfffffffd (bvmul #xffffffff C) F))
     (bvsle #x00000000 (bvadd #xfffffffd H B))
     (bvsle #x00000000 (bvadd #xfffffffd H J))
     (bvsle #x00000000 (bvadd #xfffffffd E H))
     (bvsle #x00000000 (bvadd #xfffffffd E C))
     (bvsle #x00000000 (bvadd #xfffffffd D (bvmul #xffffffff E)))
     (bvsle #x00000000 (bvadd #xfffffffd D (bvmul #xffffffff B)))
     (bvsle #x00000000 (bvadd #xfffffffd D (bvmul #xffffffff J)))
     (bvsle #x00000000 (bvadd #xfffffffd C B))
     (bvsle #x00000000 (bvadd #xfffffffd C J))
     (bvsle #x00000000 (bvadd #xfffffffe (bvmul #xffffffff H) L))
     (bvsle #x00000000 (bvadd #xfffffffe (bvmul #xffffffff H) K))
     (bvsle #x00000000 (bvadd #xfffffffe (bvmul #xffffffff H) G))
     (bvsle #x00000000 (bvadd #xfffffffe (bvmul #xffffffff E) I))
     (bvsle #x00000000 (bvadd #xfffffffe (bvmul #xffffffff E) F))
     (bvsle #x00000000 (bvadd #xfffffffe (bvmul #xffffffff C) N))
     (bvsle #x00000000 (bvadd #xfffffffe (bvmul #xffffffff C) L))
     (bvsle #x00000000 (bvadd #xfffffffe (bvmul #xffffffff C) K))
     (bvsle #x00000000 (bvadd #xfffffffe (bvmul #xffffffff C) G))
     (bvsle #x00000000 (bvadd #xfffffffe (bvmul #xffffffff C) A))
     (bvsle #x00000000 (bvadd #xfffffffe (bvmul #xffffffff B) F))
     (bvsle #x00000000 (bvadd #xfffffffe N (bvmul #xffffffff H)))
     (bvsle #x00000000 (bvadd #xfffffffe I (bvmul #xffffffff B)))
     (bvsle #x00000000 (bvadd #xfffffffe I (bvmul #xffffffff J)))
     (bvsle #x00000000 (bvadd #xfffffffe F (bvmul #xffffffff J)))
     (bvsle #x00000000 (bvadd #xfffffffe D (bvmul #xffffffff K)))
     (bvsle #x00000000 (bvadd #xfffffffe D (bvmul #xffffffff G)))
     (bvsle #x00000000 (bvadd #xfffffffe D (bvmul #xffffffff A)))
     (bvsle #x00000000 (bvadd #xfffffffe C H))
     (bvsle #x00000000 (bvadd #xfffffffe A (bvmul #xffffffff H)))
     (bvsle #x00000000 (bvadd #xffffffff (bvmul #xffffffff H) B))
     (bvsle #x00000000 (bvadd #xffffffff (bvmul #xffffffff H) J))
     (bvsle #x00000000 (bvadd #xffffffff (bvmul #xffffffff E) N))
     (bvsle #x00000000 (bvadd #xffffffff (bvmul #xffffffff E) L))
     (bvsle #x00000000 (bvadd #xffffffff (bvmul #xffffffff E) K))
     (bvsle #x00000000 (bvadd #xffffffff (bvmul #xffffffff E) G))
     (bvsle #x00000000 (bvadd #xffffffff (bvmul #xffffffff E) A))
     (bvsle #x00000000 (bvadd #xffffffff (bvmul #xffffffff C) B))
     (bvsle #x00000000 (bvadd #xffffffff (bvmul #xffffffff C) J))
     (bvsle #x00000000 (bvadd #xffffffff (bvmul #xffffffff B) L))
     (bvsle #x00000000 (bvadd #xffffffff (bvmul #xffffffff B) K))
     (bvsle #x00000000 (bvadd #xffffffff (bvmul #xffffffff B) G))
     (bvsle #x00000000 (bvadd #xffffffff (bvmul #xffffffff A) I))
     (bvsle #x00000000 (bvadd #xffffffff (bvmul #xffffffff A) F))
     (bvsle #x00000000 (bvadd #xffffffff N (bvmul #xffffffff B)))
     (bvsle #x00000000 (bvadd #xffffffff N (bvmul #xffffffff J)))
     (bvsle #x00000000 (bvadd #xffffffff L (bvmul #xffffffff J)))
     (bvsle #x00000000 (bvadd #xffffffff K (bvmul #xffffffff J)))
     (bvsle #x00000000 (bvadd #xffffffff I (bvmul #xffffffff K)))
     (bvsle #x00000000 (bvadd #xffffffff I (bvmul #xffffffff G)))
     (bvsle #x00000000 (bvadd #xffffffff G (bvmul #xffffffff J)))
     (bvsle #x00000000 (bvadd #xffffffff F (bvmul #xffffffff K)))
     (bvsle #x00000000 (bvadd #xffffffff F (bvmul #xffffffff G)))
     (bvsle #x00000000 (bvadd #xffffffff E (bvmul #xffffffff H)))
     (bvsle #x00000000 (bvadd #xffffffff E (bvmul #xffffffff C)))
     (bvsle #x00000000 (bvadd #xffffffff D (bvmul #xffffffff N)))
     (bvsle #x00000000 (bvadd #xffffffff D (bvmul #xffffffff L)))
     (bvsle #x00000000 (bvadd #xffffffff D (bvmul #xffffffff I)))
     (bvsle #x00000000 (bvadd #xffffffff D (bvmul #xffffffff F)))
     (bvsle #x00000000 (bvadd #xffffffff A (bvmul #xffffffff B)))
     (bvsle #x00000000 (bvadd #xffffffff A (bvmul #xffffffff J)))
     (bvsle #x00000000 (bvadd #x00000002 (bvmul #xffffffff N) B))
     (bvsle #x00000000 (bvadd #x00000002 (bvmul #xffffffff N) J))
     (bvsle #x00000000 (bvadd #x00000002 (bvmul #xffffffff L) J))
     (bvsle #x00000000
            (bvadd #x00000002 (bvmul #xffffffff C) (bvmul #xffffffff H)))
     (bvsle #x00000000 (bvadd #x00000002 E (bvmul #xffffffff N)))
     (bvsle #x00000000 (bvadd #x00000002 E (bvmul #xffffffff L)))
     (bvsle #x00000000 (bvadd #x00000002 B (bvmul #xffffffff L)))
     (bvsle #x00000000 (bvadd #x00000001 (bvmul #xffffffff N) K))
     (bvsle #x00000000 (bvadd #x00000001 (bvmul #xffffffff N) G))
     (bvsle #x00000000 (bvadd #x00000001 (bvmul #xffffffff N) A))
     (bvsle #x00000000 (bvadd #x00000001 (bvmul #xffffffff L) K))
     (bvsle #x00000000 (bvadd #x00000001 (bvmul #xffffffff K) J))
     (bvsle #x00000000 (bvadd #x00000001 (bvmul #xffffffff G) J))
     (bvsle #x00000000 (bvadd #x00000001 (bvmul #xffffffff D) I))
     (bvsle #x00000000 (bvadd #x00000001 (bvmul #xffffffff D) F))
     (bvsle #x00000000 (bvadd #x00000001 (bvmul #xffffffff A) B))
     (bvsle #x00000000 (bvadd #x00000001 (bvmul #xffffffff A) J))
     (bvsle #x00000000 (bvadd #x00000001 G (bvmul #xffffffff L)))
     (bvsle #x00000000 (bvadd #x00000001 E (bvmul #xffffffff K)))
     (bvsle #x00000000 (bvadd #x00000001 E (bvmul #xffffffff G)))
     (bvsle #x00000000 (bvadd #x00000001 E (bvmul #xffffffff A)))
     (bvsle #x00000000 (bvadd #x00000001 B (bvmul #xffffffff K)))
     (bvsle #x00000000 (bvadd #x00000001 B (bvmul #xffffffff G)))
     (bvsle #x00000000 (bvadd #x00000001 A (bvmul #xffffffff L)))
     (bvsle #x00000000 (bvadd #xfffffffc I))
     (bvsle #x00000000 (bvadd #xfffffffc F))
     (bvsle #x00000000 (bvadd #xfffffffb D))
     (bvsle #x00000000 (bvadd #xfffffffd N))
     (bvsle #x00000000 (bvadd #xfffffffd L))
     (bvsle #x00000000 (bvadd #xfffffffd K))
     (bvsle #x00000000 (bvadd #xfffffffd G))
     (bvsle #x00000000 (bvadd #xfffffffd A))
     (bvsle #x00000000 (bvadd #xfffffffe E))
     (bvsle #x00000000 (bvadd #xfffffffe B))
     (bvsle #x00000000 (bvadd #xfffffffe J))
     (bvsle #x00000000 (bvadd #xffffffff H))
     (bvsle #x00000000 (bvadd #xffffffff C))
     (bvsle #x00000000 (bvadd (bvmul #xffffffff N) L))
     (bvsle #x00000000 (bvadd (bvmul #xffffffff N) I))
     (bvsle #x00000000 (bvadd (bvmul #xffffffff N) F))
     (bvsle #x00000000 (bvadd (bvmul #xffffffff I) F))
     (bvsle #x00000000 (bvadd (bvmul #xffffffff G) L))
     (bvsle #x00000000 (bvadd (bvmul #xffffffff G) K))
     (bvsle #x00000000 (bvadd (bvmul #xffffffff E) B))
     (bvsle #x00000000 (bvadd (bvmul #xffffffff E) J))
     (bvsle #x00000000 (bvadd (bvmul #xffffffff C) H))
     (bvsle #x00000000 (bvadd (bvmul #xffffffff B) J))
     (bvsle #x00000000 (bvadd (bvmul #xffffffff A) L))
     (bvsle #x00000000 (bvadd (bvmul #xffffffff A) K))
     (bvsle #x00000000 (bvadd (bvmul #xffffffff A) G))
     (bvsle #x00000000 (bvadd #x00000001 (bvmul #xffffffff H)))
     (bvsle #x00000000 (bvadd #x00000001 (bvmul #xffffffff C)))
     (bvsle #x00000000 (bvadd N (bvmul #xffffffff L)))
     (bvsle #x00000000 (bvadd N (bvmul #xffffffff K)))
     (bvsle #x00000000 (bvadd N (bvmul #xffffffff G)))
     (bvsle #x00000000 (bvadd N (bvmul #xffffffff A)))
     (bvsle #x00000000 (bvadd L (bvmul #xffffffff K)))
     (bvsle #x00000000 (bvadd I (bvmul #xffffffff L)))
     (bvsle #x00000000 (bvadd I (bvmul #xffffffff F)))
     (bvsle #x00000000 (bvadd G (bvmul #xffffffff K)))
     (bvsle #x00000000 (bvadd F (bvmul #xffffffff L)))
     (bvsle #x00000000 (bvadd E (bvmul #xffffffff B)))
     (bvsle #x00000000 (bvadd E (bvmul #xffffffff J)))
     (bvsle #x00000000 (bvadd C (bvmul #xffffffff H)))
     (bvsle #x00000000 (bvadd B (bvmul #xffffffff J)))
     (bvsle #x00000000 (bvadd A (bvmul #xffffffff K)))
     (bvsle #x00000000 (bvadd A (bvmul #xffffffff G)))
     (bvsle #x00000000 (bvadd #xfffffff7 D I)))
      )
      (step_lturn N A B C D E F G H I J K L M)
    )
  )
)
(assert
  (forall ( (A (_ BitVec 32)) (B (_ BitVec 32)) (C (_ BitVec 32)) (D (_ BitVec 32)) (E (_ BitVec 32)) (F (_ BitVec 32)) (G (_ BitVec 32)) (H (_ BitVec 32)) (I (_ BitVec 32)) (J (_ BitVec 32)) (K (_ BitVec 32)) (L (_ BitVec 32)) (M (_ BitVec 32)) (N (_ BitVec 32)) ) 
    (=>
      (and
        (lturn N A B C D E F G H I J K L M)
        true
      )
      (combined_lturn N A B C D E F G H I J K L M)
    )
  )
)
(assert
  (forall ( (A (_ BitVec 32)) (B (_ BitVec 32)) (C (_ BitVec 32)) (D (_ BitVec 32)) (E (_ BitVec 32)) (F (_ BitVec 32)) (G (_ BitVec 32)) (H (_ BitVec 32)) (I (_ BitVec 32)) (J (_ BitVec 32)) (K (_ BitVec 32)) (L (_ BitVec 32)) (M (_ BitVec 32)) (N (_ BitVec 32)) ) 
    (=>
      (and
        (step_lturn N A B C D E F G H I J K L M)
        true
      )
      (combined_lturn N A B C D E F G H I J K L M)
    )
  )
)
(assert
  (forall ( (A (_ BitVec 32)) (B (_ BitVec 32)) (C (_ BitVec 32)) (D (_ BitVec 32)) (E (_ BitVec 32)) (F (_ BitVec 32)) (G (_ BitVec 32)) (H (_ BitVec 32)) (I (_ BitVec 32)) (J (_ BitVec 32)) (K (_ BitVec 32)) (L (_ BitVec 32)) (M (_ BitVec 32)) (N (_ BitVec 32)) ) 
    (=>
      (and
        (step_lturn K A B C D E F G H I M L N J)
        true
      )
      (lturn K A B C D E F G H I N M L J)
    )
  )
)
(assert
  (forall ( (A (_ BitVec 32)) (B (_ BitVec 32)) (C (_ BitVec 32)) (D (_ BitVec 32)) (E (_ BitVec 32)) (F (_ BitVec 32)) (G (_ BitVec 32)) (H (_ BitVec 32)) (I (_ BitVec 32)) (J (_ BitVec 32)) (K (_ BitVec 32)) (L (_ BitVec 32)) (M (_ BitVec 32)) (N (_ BitVec 32)) (v_14 (_ BitVec 32)) (v_15 (_ BitVec 32)) (v_16 (_ BitVec 32)) ) 
    (=>
      (and
        (combined_lturn K A B C D E F G H I v_14 L N J)
        (step_lturn K A B C D E F G H I v_15 M L J)
        (combined_lturn K A B C D E F G H I v_16 N M J)
        (and (= v_14 K) (= v_15 K) (= v_16 K))
      )
      (lturn K A B C D E F G H I N M L J)
    )
  )
)
(assert
  (forall ( (A (_ BitVec 32)) (B (_ BitVec 32)) (C (_ BitVec 32)) (D (_ BitVec 32)) (E (_ BitVec 32)) (F (_ BitVec 32)) (G (_ BitVec 32)) (H (_ BitVec 32)) (I (_ BitVec 32)) (J (_ BitVec 32)) (K (_ BitVec 32)) (L (_ BitVec 32)) (M (_ BitVec 32)) (N (_ BitVec 32)) (v_14 (_ BitVec 32)) (v_15 (_ BitVec 32)) (v_16 (_ BitVec 32)) ) 
    (=>
      (and
        (combined_lturn K A B C D E F G H I v_14 L N J)
        (combined_lturn K A B C D E F G H I v_15 M L J)
        (step_lturn K A B C D E F G H I v_16 N M J)
        (and (= v_14 K) (= v_15 K) (= v_16 K))
      )
      (lturn K A B C D E F G H I N M L J)
    )
  )
)
(assert
  (forall ( (A (_ BitVec 32)) (B (_ BitVec 32)) (C (_ BitVec 32)) (D (_ BitVec 32)) (E (_ BitVec 32)) (F (_ BitVec 32)) (G (_ BitVec 32)) (H (_ BitVec 32)) (I (_ BitVec 32)) (J (_ BitVec 32)) (K (_ BitVec 32)) (L (_ BitVec 32)) (M (_ BitVec 32)) (N (_ BitVec 32)) (v_14 (_ BitVec 32)) (v_15 (_ BitVec 32)) (v_16 (_ BitVec 32)) ) 
    (=>
      (and
        (step_lturn K A B C D E F G H I v_14 L N J)
        (combined_lturn K A B C D E F G H I v_15 M L J)
        (combined_lturn K A B C D E F G H I v_16 N M J)
        (and (= v_14 K) (= v_15 K) (= v_16 K))
      )
      (lturn K A B C D E F G H I N M L J)
    )
  )
)
(assert
  (forall ( (A (_ BitVec 32)) (B (_ BitVec 32)) (C (_ BitVec 32)) (D (_ BitVec 32)) (E (_ BitVec 32)) (F (_ BitVec 32)) (G (_ BitVec 32)) (H (_ BitVec 32)) (I (_ BitVec 32)) (J (_ BitVec 32)) (K (_ BitVec 32)) (L (_ BitVec 32)) (M (_ BitVec 32)) (N (_ BitVec 32)) (O (_ BitVec 32)) (v_15 (_ BitVec 32)) (v_16 (_ BitVec 32)) (v_17 (_ BitVec 32)) ) 
    (=>
      (and
        (combined_lturn L A B C D E F G H I K N v_15 J)
        (step_lturn L A B C D E F G H I O N M J)
        (combined_lturn L A B C D E F G H I v_16 N M J)
        (combined_lturn L A B C D E F G H I v_17 O N J)
        (combined_lturn L A B C D E F G H I K O N J)
        (and (= v_15 L) (= v_16 L) (= v_17 L))
      )
      (lturn L A B C D E F G H I K N M J)
    )
  )
)
(assert
  (forall ( (A (_ BitVec 32)) (B (_ BitVec 32)) (C (_ BitVec 32)) (D (_ BitVec 32)) (E (_ BitVec 32)) (F (_ BitVec 32)) (G (_ BitVec 32)) (H (_ BitVec 32)) (I (_ BitVec 32)) (J (_ BitVec 32)) (K (_ BitVec 32)) (L (_ BitVec 32)) (M (_ BitVec 32)) (N (_ BitVec 32)) (O (_ BitVec 32)) (v_15 (_ BitVec 32)) (v_16 (_ BitVec 32)) (v_17 (_ BitVec 32)) ) 
    (=>
      (and
        (combined_lturn L A B C D E F G H I K N v_15 J)
        (combined_lturn L A B C D E F G H I O N M J)
        (step_lturn L A B C D E F G H I v_16 N M J)
        (combined_lturn L A B C D E F G H I v_17 O N J)
        (combined_lturn L A B C D E F G H I K O N J)
        (and (= v_15 L) (= v_16 L) (= v_17 L))
      )
      (lturn L A B C D E F G H I K N M J)
    )
  )
)
(assert
  (forall ( (A (_ BitVec 32)) (B (_ BitVec 32)) (C (_ BitVec 32)) (D (_ BitVec 32)) (E (_ BitVec 32)) (F (_ BitVec 32)) (G (_ BitVec 32)) (H (_ BitVec 32)) (I (_ BitVec 32)) (J (_ BitVec 32)) (K (_ BitVec 32)) (L (_ BitVec 32)) (M (_ BitVec 32)) (N (_ BitVec 32)) (O (_ BitVec 32)) (v_15 (_ BitVec 32)) (v_16 (_ BitVec 32)) (v_17 (_ BitVec 32)) ) 
    (=>
      (and
        (combined_lturn L A B C D E F G H I K N v_15 J)
        (combined_lturn L A B C D E F G H I O N M J)
        (combined_lturn L A B C D E F G H I v_16 N M J)
        (step_lturn L A B C D E F G H I v_17 O N J)
        (combined_lturn L A B C D E F G H I K O N J)
        (and (= v_15 L) (= v_16 L) (= v_17 L))
      )
      (lturn L A B C D E F G H I K N M J)
    )
  )
)
(assert
  (forall ( (A (_ BitVec 32)) (B (_ BitVec 32)) (C (_ BitVec 32)) (D (_ BitVec 32)) (E (_ BitVec 32)) (F (_ BitVec 32)) (G (_ BitVec 32)) (H (_ BitVec 32)) (I (_ BitVec 32)) (J (_ BitVec 32)) (K (_ BitVec 32)) (L (_ BitVec 32)) (M (_ BitVec 32)) (N (_ BitVec 32)) (O (_ BitVec 32)) (v_15 (_ BitVec 32)) (v_16 (_ BitVec 32)) (v_17 (_ BitVec 32)) ) 
    (=>
      (and
        (combined_lturn L A B C D E F G H I K N v_15 J)
        (combined_lturn L A B C D E F G H I O N M J)
        (combined_lturn L A B C D E F G H I v_16 N M J)
        (combined_lturn L A B C D E F G H I v_17 O N J)
        (step_lturn L A B C D E F G H I K O N J)
        (and (= v_15 L) (= v_16 L) (= v_17 L))
      )
      (lturn L A B C D E F G H I K N M J)
    )
  )
)
(assert
  (forall ( (A (_ BitVec 32)) (B (_ BitVec 32)) (C (_ BitVec 32)) (D (_ BitVec 32)) (E (_ BitVec 32)) (F (_ BitVec 32)) (G (_ BitVec 32)) (H (_ BitVec 32)) (I (_ BitVec 32)) (J (_ BitVec 32)) (K (_ BitVec 32)) (L (_ BitVec 32)) (M (_ BitVec 32)) (N (_ BitVec 32)) (O (_ BitVec 32)) (v_15 (_ BitVec 32)) (v_16 (_ BitVec 32)) (v_17 (_ BitVec 32)) ) 
    (=>
      (and
        (step_lturn L A B C D E F G H I K N v_15 J)
        (combined_lturn L A B C D E F G H I O N M J)
        (combined_lturn L A B C D E F G H I v_16 N M J)
        (combined_lturn L A B C D E F G H I v_17 O N J)
        (combined_lturn L A B C D E F G H I K O N J)
        (and (= v_15 L) (= v_16 L) (= v_17 L))
      )
      (lturn L A B C D E F G H I K N M J)
    )
  )
)
(assert
  (forall ( (A (_ BitVec 32)) (B (_ BitVec 32)) (C (_ BitVec 32)) (D (_ BitVec 32)) (E (_ BitVec 32)) (F (_ BitVec 32)) (G (_ BitVec 32)) (H (_ BitVec 32)) (I (_ BitVec 32)) (J (_ BitVec 32)) (K (_ BitVec 32)) (L (_ BitVec 32)) (M (_ BitVec 32)) (N (_ BitVec 32)) ) 
    (=>
      (and
        (step_lturn K A B C D E F G H I M L N J)
        true
      )
      (step_lturn K A B C D E F G H I N M L J)
    )
  )
)
(assert
  (forall ( (A (_ BitVec 32)) (B (_ BitVec 32)) (C (_ BitVec 32)) (D (_ BitVec 32)) (E (_ BitVec 32)) (F (_ BitVec 32)) (G (_ BitVec 32)) (H (_ BitVec 32)) (I (_ BitVec 32)) (J (_ BitVec 32)) (K (_ BitVec 32)) (L (_ BitVec 32)) (M (_ BitVec 32)) (N (_ BitVec 32)) (v_14 (_ BitVec 32)) (v_15 (_ BitVec 32)) (v_16 (_ BitVec 32)) ) 
    (=>
      (and
        (combined_lturn K A B C D E F G H I v_14 L N J)
        (step_lturn K A B C D E F G H I v_15 M L J)
        (combined_lturn K A B C D E F G H I v_16 N M J)
        (and (= v_14 K) (= v_15 K) (= v_16 K))
      )
      (step_lturn K A B C D E F G H I N M L J)
    )
  )
)
(assert
  (forall ( (A (_ BitVec 32)) (B (_ BitVec 32)) (C (_ BitVec 32)) (D (_ BitVec 32)) (E (_ BitVec 32)) (F (_ BitVec 32)) (G (_ BitVec 32)) (H (_ BitVec 32)) (I (_ BitVec 32)) (J (_ BitVec 32)) (K (_ BitVec 32)) (L (_ BitVec 32)) (M (_ BitVec 32)) (N (_ BitVec 32)) (v_14 (_ BitVec 32)) (v_15 (_ BitVec 32)) (v_16 (_ BitVec 32)) ) 
    (=>
      (and
        (combined_lturn K A B C D E F G H I v_14 L N J)
        (combined_lturn K A B C D E F G H I v_15 M L J)
        (step_lturn K A B C D E F G H I v_16 N M J)
        (and (= v_14 K) (= v_15 K) (= v_16 K))
      )
      (step_lturn K A B C D E F G H I N M L J)
    )
  )
)
(assert
  (forall ( (A (_ BitVec 32)) (B (_ BitVec 32)) (C (_ BitVec 32)) (D (_ BitVec 32)) (E (_ BitVec 32)) (F (_ BitVec 32)) (G (_ BitVec 32)) (H (_ BitVec 32)) (I (_ BitVec 32)) (J (_ BitVec 32)) (K (_ BitVec 32)) (L (_ BitVec 32)) (M (_ BitVec 32)) (N (_ BitVec 32)) (v_14 (_ BitVec 32)) (v_15 (_ BitVec 32)) (v_16 (_ BitVec 32)) ) 
    (=>
      (and
        (step_lturn K A B C D E F G H I v_14 L N J)
        (combined_lturn K A B C D E F G H I v_15 M L J)
        (combined_lturn K A B C D E F G H I v_16 N M J)
        (and (= v_14 K) (= v_15 K) (= v_16 K))
      )
      (step_lturn K A B C D E F G H I N M L J)
    )
  )
)
(assert
  (forall ( (A (_ BitVec 32)) (B (_ BitVec 32)) (C (_ BitVec 32)) (D (_ BitVec 32)) (E (_ BitVec 32)) (F (_ BitVec 32)) (G (_ BitVec 32)) (H (_ BitVec 32)) (I (_ BitVec 32)) (J (_ BitVec 32)) (K (_ BitVec 32)) (L (_ BitVec 32)) (M (_ BitVec 32)) (N (_ BitVec 32)) (O (_ BitVec 32)) (v_15 (_ BitVec 32)) (v_16 (_ BitVec 32)) (v_17 (_ BitVec 32)) ) 
    (=>
      (and
        (combined_lturn L A B C D E F G H I K N v_15 J)
        (step_lturn L A B C D E F G H I O N M J)
        (combined_lturn L A B C D E F G H I v_16 N M J)
        (combined_lturn L A B C D E F G H I v_17 O N J)
        (combined_lturn L A B C D E F G H I K O N J)
        (and (= v_15 L) (= v_16 L) (= v_17 L))
      )
      (step_lturn L A B C D E F G H I K N M J)
    )
  )
)
(assert
  (forall ( (A (_ BitVec 32)) (B (_ BitVec 32)) (C (_ BitVec 32)) (D (_ BitVec 32)) (E (_ BitVec 32)) (F (_ BitVec 32)) (G (_ BitVec 32)) (H (_ BitVec 32)) (I (_ BitVec 32)) (J (_ BitVec 32)) (K (_ BitVec 32)) (L (_ BitVec 32)) (M (_ BitVec 32)) (N (_ BitVec 32)) (O (_ BitVec 32)) (v_15 (_ BitVec 32)) (v_16 (_ BitVec 32)) (v_17 (_ BitVec 32)) ) 
    (=>
      (and
        (combined_lturn L A B C D E F G H I K N v_15 J)
        (combined_lturn L A B C D E F G H I O N M J)
        (step_lturn L A B C D E F G H I v_16 N M J)
        (combined_lturn L A B C D E F G H I v_17 O N J)
        (combined_lturn L A B C D E F G H I K O N J)
        (and (= v_15 L) (= v_16 L) (= v_17 L))
      )
      (step_lturn L A B C D E F G H I K N M J)
    )
  )
)
(assert
  (forall ( (A (_ BitVec 32)) (B (_ BitVec 32)) (C (_ BitVec 32)) (D (_ BitVec 32)) (E (_ BitVec 32)) (F (_ BitVec 32)) (G (_ BitVec 32)) (H (_ BitVec 32)) (I (_ BitVec 32)) (J (_ BitVec 32)) (K (_ BitVec 32)) (L (_ BitVec 32)) (M (_ BitVec 32)) (N (_ BitVec 32)) (O (_ BitVec 32)) (v_15 (_ BitVec 32)) (v_16 (_ BitVec 32)) (v_17 (_ BitVec 32)) ) 
    (=>
      (and
        (combined_lturn L A B C D E F G H I K N v_15 J)
        (combined_lturn L A B C D E F G H I O N M J)
        (combined_lturn L A B C D E F G H I v_16 N M J)
        (step_lturn L A B C D E F G H I v_17 O N J)
        (combined_lturn L A B C D E F G H I K O N J)
        (and (= v_15 L) (= v_16 L) (= v_17 L))
      )
      (step_lturn L A B C D E F G H I K N M J)
    )
  )
)
(assert
  (forall ( (A (_ BitVec 32)) (B (_ BitVec 32)) (C (_ BitVec 32)) (D (_ BitVec 32)) (E (_ BitVec 32)) (F (_ BitVec 32)) (G (_ BitVec 32)) (H (_ BitVec 32)) (I (_ BitVec 32)) (J (_ BitVec 32)) (K (_ BitVec 32)) (L (_ BitVec 32)) (M (_ BitVec 32)) (N (_ BitVec 32)) (O (_ BitVec 32)) (v_15 (_ BitVec 32)) (v_16 (_ BitVec 32)) (v_17 (_ BitVec 32)) ) 
    (=>
      (and
        (combined_lturn L A B C D E F G H I K N v_15 J)
        (combined_lturn L A B C D E F G H I O N M J)
        (combined_lturn L A B C D E F G H I v_16 N M J)
        (combined_lturn L A B C D E F G H I v_17 O N J)
        (step_lturn L A B C D E F G H I K O N J)
        (and (= v_15 L) (= v_16 L) (= v_17 L))
      )
      (step_lturn L A B C D E F G H I K N M J)
    )
  )
)
(assert
  (forall ( (A (_ BitVec 32)) (B (_ BitVec 32)) (C (_ BitVec 32)) (D (_ BitVec 32)) (E (_ BitVec 32)) (F (_ BitVec 32)) (G (_ BitVec 32)) (H (_ BitVec 32)) (I (_ BitVec 32)) (J (_ BitVec 32)) (K (_ BitVec 32)) (L (_ BitVec 32)) (M (_ BitVec 32)) (N (_ BitVec 32)) (O (_ BitVec 32)) (v_15 (_ BitVec 32)) (v_16 (_ BitVec 32)) (v_17 (_ BitVec 32)) ) 
    (=>
      (and
        (step_lturn L A B C D E F G H I K N v_15 J)
        (combined_lturn L A B C D E F G H I O N M J)
        (combined_lturn L A B C D E F G H I v_16 N M J)
        (combined_lturn L A B C D E F G H I v_17 O N J)
        (combined_lturn L A B C D E F G H I K O N J)
        (and (= v_15 L) (= v_16 L) (= v_17 L))
      )
      (step_lturn L A B C D E F G H I K N M J)
    )
  )
)
(assert
  (forall ( (A (_ BitVec 32)) (B (_ BitVec 32)) (C (_ BitVec 32)) (D (_ BitVec 32)) (E (_ BitVec 32)) (F (_ BitVec 32)) (G (_ BitVec 32)) (H (_ BitVec 32)) (I (_ BitVec 32)) (J (_ BitVec 32)) (K (_ BitVec 32)) (L (_ BitVec 32)) (M (_ BitVec 32)) (N (_ BitVec 32)) (O (_ BitVec 32)) (v_15 (_ BitVec 32)) (v_16 (_ BitVec 32)) (v_17 (_ BitVec 32)) ) 
    (=>
      (and
        (combined_lturn L A B C D E F G H I K N v_15 J)
        (step_lturn L A B C D E F G H I K M N J)
        (combined_lturn L A B C D E F G H I O N M J)
        (combined_lturn L A B C D E F G H I v_16 N M J)
        (combined_lturn L A B C D E F G H I v_17 O N J)
        (combined_lturn L A B C D E F G H I K O N J)
        (and (= v_15 L) (= v_16 L) (= v_17 L))
      )
      CHC_COMP_FALSE
    )
  )
)
(assert
  (forall ( (A (_ BitVec 32)) (B (_ BitVec 32)) (C (_ BitVec 32)) (D (_ BitVec 32)) (E (_ BitVec 32)) (F (_ BitVec 32)) (G (_ BitVec 32)) (H (_ BitVec 32)) (I (_ BitVec 32)) (J (_ BitVec 32)) (K (_ BitVec 32)) (L (_ BitVec 32)) (M (_ BitVec 32)) (N (_ BitVec 32)) (O (_ BitVec 32)) (v_15 (_ BitVec 32)) (v_16 (_ BitVec 32)) (v_17 (_ BitVec 32)) ) 
    (=>
      (and
        (step_lturn L A B C D E F G H I K N v_15 J)
        (combined_lturn L A B C D E F G H I K M N J)
        (combined_lturn L A B C D E F G H I O N M J)
        (combined_lturn L A B C D E F G H I v_16 N M J)
        (combined_lturn L A B C D E F G H I v_17 O N J)
        (combined_lturn L A B C D E F G H I K O N J)
        (and (= v_15 L) (= v_16 L) (= v_17 L))
      )
      CHC_COMP_FALSE
    )
  )
)
(assert
  (forall ( (A (_ BitVec 32)) (B (_ BitVec 32)) (C (_ BitVec 32)) (D (_ BitVec 32)) (E (_ BitVec 32)) (F (_ BitVec 32)) (G (_ BitVec 32)) (H (_ BitVec 32)) (I (_ BitVec 32)) (J (_ BitVec 32)) (K (_ BitVec 32)) (L (_ BitVec 32)) (M (_ BitVec 32)) (N (_ BitVec 32)) (O (_ BitVec 32)) (v_15 (_ BitVec 32)) (v_16 (_ BitVec 32)) (v_17 (_ BitVec 32)) ) 
    (=>
      (and
        (combined_lturn L A B C D E F G H I K N v_15 J)
        (combined_lturn L A B C D E F G H I K M N J)
        (combined_lturn L A B C D E F G H I O N M J)
        (combined_lturn L A B C D E F G H I v_16 N M J)
        (combined_lturn L A B C D E F G H I v_17 O N J)
        (step_lturn L A B C D E F G H I K O N J)
        (and (= v_15 L) (= v_16 L) (= v_17 L))
      )
      CHC_COMP_FALSE
    )
  )
)
(assert
  (forall ( (A (_ BitVec 32)) (B (_ BitVec 32)) (C (_ BitVec 32)) (D (_ BitVec 32)) (E (_ BitVec 32)) (F (_ BitVec 32)) (G (_ BitVec 32)) (H (_ BitVec 32)) (I (_ BitVec 32)) (J (_ BitVec 32)) (K (_ BitVec 32)) (L (_ BitVec 32)) (M (_ BitVec 32)) (N (_ BitVec 32)) (O (_ BitVec 32)) (v_15 (_ BitVec 32)) (v_16 (_ BitVec 32)) (v_17 (_ BitVec 32)) ) 
    (=>
      (and
        (combined_lturn L A B C D E F G H I K N v_15 J)
        (combined_lturn L A B C D E F G H I K M N J)
        (combined_lturn L A B C D E F G H I O N M J)
        (combined_lturn L A B C D E F G H I v_16 N M J)
        (step_lturn L A B C D E F G H I v_17 O N J)
        (combined_lturn L A B C D E F G H I K O N J)
        (and (= v_15 L) (= v_16 L) (= v_17 L))
      )
      CHC_COMP_FALSE
    )
  )
)
(assert
  (forall ( (A (_ BitVec 32)) (B (_ BitVec 32)) (C (_ BitVec 32)) (D (_ BitVec 32)) (E (_ BitVec 32)) (F (_ BitVec 32)) (G (_ BitVec 32)) (H (_ BitVec 32)) (I (_ BitVec 32)) (J (_ BitVec 32)) (K (_ BitVec 32)) (L (_ BitVec 32)) (M (_ BitVec 32)) (N (_ BitVec 32)) (O (_ BitVec 32)) (v_15 (_ BitVec 32)) (v_16 (_ BitVec 32)) (v_17 (_ BitVec 32)) ) 
    (=>
      (and
        (combined_lturn L A B C D E F G H I K N v_15 J)
        (combined_lturn L A B C D E F G H I K M N J)
        (combined_lturn L A B C D E F G H I O N M J)
        (step_lturn L A B C D E F G H I v_16 N M J)
        (combined_lturn L A B C D E F G H I v_17 O N J)
        (combined_lturn L A B C D E F G H I K O N J)
        (and (= v_15 L) (= v_16 L) (= v_17 L))
      )
      CHC_COMP_FALSE
    )
  )
)
(assert
  (forall ( (A (_ BitVec 32)) (B (_ BitVec 32)) (C (_ BitVec 32)) (D (_ BitVec 32)) (E (_ BitVec 32)) (F (_ BitVec 32)) (G (_ BitVec 32)) (H (_ BitVec 32)) (I (_ BitVec 32)) (J (_ BitVec 32)) (K (_ BitVec 32)) (L (_ BitVec 32)) (M (_ BitVec 32)) (N (_ BitVec 32)) (O (_ BitVec 32)) (v_15 (_ BitVec 32)) (v_16 (_ BitVec 32)) (v_17 (_ BitVec 32)) ) 
    (=>
      (and
        (combined_lturn L A B C D E F G H I K N v_15 J)
        (combined_lturn L A B C D E F G H I K M N J)
        (step_lturn L A B C D E F G H I O N M J)
        (combined_lturn L A B C D E F G H I v_16 N M J)
        (combined_lturn L A B C D E F G H I v_17 O N J)
        (combined_lturn L A B C D E F G H I K O N J)
        (and (= v_15 L) (= v_16 L) (= v_17 L))
      )
      CHC_COMP_FALSE
    )
  )
)
(assert
  (forall ( (A (_ BitVec 32)) (B (_ BitVec 32)) (C (_ BitVec 32)) (D (_ BitVec 32)) (E (_ BitVec 32)) (F (_ BitVec 32)) (G (_ BitVec 32)) (H (_ BitVec 32)) (I (_ BitVec 32)) (J (_ BitVec 32)) (K (_ BitVec 32)) (L (_ BitVec 32)) (M (_ BitVec 32)) (N (_ BitVec 32)) (v_14 (_ BitVec 32)) (v_15 (_ BitVec 32)) (v_16 (_ BitVec 32)) ) 
    (=>
      (and
        (combined_lturn K A B C D E F G H I v_14 L N J)
        (step_lturn K A B C D E F G H I N L M J)
        (combined_lturn K A B C D E F G H I v_15 M L J)
        (combined_lturn K A B C D E F G H I v_16 N M J)
        (and (= v_14 K) (= v_15 K) (= v_16 K))
      )
      CHC_COMP_FALSE
    )
  )
)
(assert
  (forall ( (A (_ BitVec 32)) (B (_ BitVec 32)) (C (_ BitVec 32)) (D (_ BitVec 32)) (E (_ BitVec 32)) (F (_ BitVec 32)) (G (_ BitVec 32)) (H (_ BitVec 32)) (I (_ BitVec 32)) (J (_ BitVec 32)) (K (_ BitVec 32)) (L (_ BitVec 32)) (M (_ BitVec 32)) (N (_ BitVec 32)) (v_14 (_ BitVec 32)) (v_15 (_ BitVec 32)) (v_16 (_ BitVec 32)) ) 
    (=>
      (and
        (step_lturn K A B C D E F G H I v_14 L N J)
        (combined_lturn K A B C D E F G H I N L M J)
        (combined_lturn K A B C D E F G H I v_15 M L J)
        (combined_lturn K A B C D E F G H I v_16 N M J)
        (and (= v_14 K) (= v_15 K) (= v_16 K))
      )
      CHC_COMP_FALSE
    )
  )
)
(assert
  (forall ( (A (_ BitVec 32)) (B (_ BitVec 32)) (C (_ BitVec 32)) (D (_ BitVec 32)) (E (_ BitVec 32)) (F (_ BitVec 32)) (G (_ BitVec 32)) (H (_ BitVec 32)) (I (_ BitVec 32)) (J (_ BitVec 32)) (K (_ BitVec 32)) (L (_ BitVec 32)) (M (_ BitVec 32)) (N (_ BitVec 32)) (v_14 (_ BitVec 32)) (v_15 (_ BitVec 32)) (v_16 (_ BitVec 32)) ) 
    (=>
      (and
        (combined_lturn K A B C D E F G H I v_14 L N J)
        (combined_lturn K A B C D E F G H I N L M J)
        (combined_lturn K A B C D E F G H I v_15 M L J)
        (step_lturn K A B C D E F G H I v_16 N M J)
        (and (= v_14 K) (= v_15 K) (= v_16 K))
      )
      CHC_COMP_FALSE
    )
  )
)
(assert
  (forall ( (A (_ BitVec 32)) (B (_ BitVec 32)) (C (_ BitVec 32)) (D (_ BitVec 32)) (E (_ BitVec 32)) (F (_ BitVec 32)) (G (_ BitVec 32)) (H (_ BitVec 32)) (I (_ BitVec 32)) (J (_ BitVec 32)) (K (_ BitVec 32)) (L (_ BitVec 32)) (M (_ BitVec 32)) (N (_ BitVec 32)) (v_14 (_ BitVec 32)) (v_15 (_ BitVec 32)) (v_16 (_ BitVec 32)) ) 
    (=>
      (and
        (combined_lturn K A B C D E F G H I v_14 L N J)
        (combined_lturn K A B C D E F G H I N L M J)
        (step_lturn K A B C D E F G H I v_15 M L J)
        (combined_lturn K A B C D E F G H I v_16 N M J)
        (and (= v_14 K) (= v_15 K) (= v_16 K))
      )
      CHC_COMP_FALSE
    )
  )
)
(assert
  (forall ( (A (_ BitVec 32)) (B (_ BitVec 32)) (C (_ BitVec 32)) (D (_ BitVec 32)) (E (_ BitVec 32)) (F (_ BitVec 32)) (G (_ BitVec 32)) (H (_ BitVec 32)) (I (_ BitVec 32)) (J (_ BitVec 32)) (K (_ BitVec 32)) (L (_ BitVec 32)) (M (_ BitVec 32)) (N (_ BitVec 32)) ) 
    (=>
      (and
        (combined_lturn K A B C D E F G H I N M L J)
        (step_lturn K A B C D E F G H I N L M J)
        true
      )
      CHC_COMP_FALSE
    )
  )
)
(assert
  (forall ( (A (_ BitVec 32)) (B (_ BitVec 32)) (C (_ BitVec 32)) (D (_ BitVec 32)) (E (_ BitVec 32)) (F (_ BitVec 32)) (G (_ BitVec 32)) (H (_ BitVec 32)) (I (_ BitVec 32)) (J (_ BitVec 32)) (K (_ BitVec 32)) (L (_ BitVec 32)) (M (_ BitVec 32)) (N (_ BitVec 32)) ) 
    (=>
      (and
        (step_lturn K A B C D E F G H I N M L J)
        (combined_lturn K A B C D E F G H I N L M J)
        true
      )
      CHC_COMP_FALSE
    )
  )
)
(assert
  (forall ( (CHC_COMP_UNUSED Bool) ) 
    (=>
      (and
        CHC_COMP_FALSE
      )
      false
    )
  )
)

(check-sat)
(exit)
